{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03cbow.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sIfU8pJW2BDS","colab_type":"code","outputId":"17dbc38e-a107-43d7-9a5f-395b32047a39","executionInfo":{"status":"ok","timestamp":1554691319977,"user_tz":-480,"elapsed":7802,"user":{"displayName":"Siyao Jiang","photoUrl":"","userId":"03459425685119894863"}},"colab":{"base_uri":"https://localhost:8080/","height":397}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","!pip install tensorflow-gpu==2.0.0-alpha0\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","print (device_name)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n","Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.4)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.9.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","/device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"DNaSBNNEegl4","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import time\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CMYg_Wuq8M3P","colab_type":"code","outputId":"491bbb11-fde8-49bf-ed33-255b74fef932","executionInfo":{"status":"ok","timestamp":1554691322376,"user_tz":-480,"elapsed":10167,"user":{"displayName":"Siyao Jiang","photoUrl":"","userId":"03459425685119894863"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"metadata":{"id":"DG7RwLJjZjdN","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 128\n","emb_size = 100\n","ngram = 3\n","lr = 1e-3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bxXRWDeU8MJO","colab_type":"code","colab":{}},"cell_type":"code","source":["train_path = '/content/drive/My Drive/Colab Notebooks/cs11747/data/lm/train.txt' # train set\n","dev_path = '/content/drive/My Drive/Colab Notebooks/cs11747/data/lm/valid.txt' # dev set\n","embed_path = '/content/drive/My Drive/Colab Notebooks/cs11747/3/embeddings.tsv' # word vector\n","words_path = '/content/drive/My Drive/Colab Notebooks/cs11747/3/labels.tsv' # words"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x5pWyGKIz5h6","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_dataset(filename):\n","    with open(filename, \"r\") as f:\n","        data = []\n","        for line in f:\n","            words = line.lower().strip()\n","            data.append(words)\n","        return data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"alGOxQuM5F4R","colab_type":"code","colab":{}},"cell_type":"code","source":["train_set = read_dataset(train_path)\n","random.shuffle(train_set)\n","dev_set = read_dataset(dev_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ryQ1UiUBx8LP","colab_type":"code","colab":{}},"cell_type":"code","source":["tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n","tokenizer.fit_on_texts(train_set)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UHLyn0h1Ce7N","colab_type":"code","outputId":"698b4fd3-090e-4b1e-8f67-bb1f542422f6","executionInfo":{"status":"ok","timestamp":1554691323738,"user_tz":-480,"elapsed":11466,"user":{"displayName":"Siyao Jiang","photoUrl":"","userId":"03459425685119894863"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["word_index = tokenizer.word_index\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","nwords = len(word_index)\n","print (nwords)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["9649\n"],"name":"stdout"}]},{"metadata":{"id":"m5G-VOxPlmhQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_gen(batch_size=batch_size):\n","    steps = len(train_set) // batch_size\n","    for step in range(steps):\n","        train_seq = tokenizer.texts_to_sequences(train_set[step:step+batch_size])\n","        yield train_seq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DY4TgO-BDEQ1","colab_type":"code","colab":{}},"cell_type":"code","source":["def dev_gen(batch_size=batch_size):\n","    steps = len(dev_set) // batch_size\n","    for step in range(steps):\n","        dev_seq = tokenizer.texts_to_sequences(dev_set[step:step+batch_size])\n","        yield dev_seq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CG-wy0-nLTCS","colab_type":"code","colab":{}},"cell_type":"code","source":["class WordEmbCBOW(tf.keras.Model):\n","    def __init__(self, nwords, emb_size):\n","        super(WordEmbCBOW, self).__init__()\n","        self.embed = tf.keras.layers.Embedding(nwords+1, emb_size, trainable=True)\n","        self.dense = tf.keras.layers.Dense(nwords+1, activation='softmax')\n","\n","    @tf.function\n","    def call(self, x):\n","        \"\"\"Run the model.\"\"\"\n","        result = self.embed(x)\n","        result = tf.reduce_sum(result, axis=1)\n","        result = self.dense(result)\n","\n","        return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mazHuxpwZQim","colab_type":"code","colab":{}},"cell_type":"code","source":["model = WordEmbCBOW(nwords, emb_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D73f_jv7cis_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Calculate the loss value for the whole batch of sentences\n","def sent_loss(sents):\n","    all_windows = []\n","    all_targets = []\n","    for sent in sents:\n","        padded = [0] * ngram + sent + [0] * ngram\n","        for i in range(ngram, len(sent) + ngram):\n","            window = padded[i-ngram:i] + padded[i+1:i+ngram+1]\n","            all_windows.append(window)\n","            all_targets.append(padded[i])\n","\n","    all_windows = tf.Variable(all_windows, trainable=False)\n","    all_targets = tf.Variable(all_targets, trainable=False)\n","    logits = model(all_windows)\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.losses.Reduction.SUM)\n","    loss = loss_fn(all_targets, logits)\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2mH34W35lGVu","colab_type":"code","outputId":"c02f9f49-e0e1-42b2-b9c5-451e2a17fa04","executionInfo":{"status":"error","timestamp":1554691631198,"user_tz":-480,"elapsed":318854,"user":{"displayName":"Siyao Jiang","photoUrl":"","userId":"03459425685119894863"}},"colab":{"base_uri":"https://localhost:8080/","height":1721}},"cell_type":"code","source":["last_dev = 1e20\n","best_dev = 1e20\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# Iterate over epochs.\n","for epoch in range(15):\n","    print('Start of epoch %d' % (epoch,))\n","    start = time.time()\n","    train_loss = 0\n","    train_words = 0\n","    batch_id = 0\n","    for sents in train_gen():\n","\n","        # Open a GradientTape to record the operations run during the forward pass, which enables autodifferentiation.\n","        with tf.GradientTape() as tape:\n","\n","            loss = sent_loss(sents)\n","            train_loss += loss\n","            batch_words = sum(list(map(len, sents)))\n","            train_words += batch_words\n","\n","            # Use the gradient tape to automatically retrieve the gradients of the trainable weights with respect to the loss.\n","            grads = tape.gradient(loss, model.trainable_variables)\n","\n","            # Run one step of gradient descent by updating the value of the weights to minimize the loss.\n","            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","            # Log every 50 batch.\n","            batch_id += 1\n","            if batch_id % 50 == 0:\n","                print('Training time: %0.3f seconds, training loss at sentence %d: %0.4f' % (time.time()-start, batch_id*batch_size, loss/batch_words))\n","                \n","    print ('Epoch %d: Training time=%0.3f seconds, training loss per word=%0.4f' % (epoch, time.time()-start, train_loss/train_words))\n","    \n","    # Evaluate on dev set\n","    dev_words, dev_loss = 0, 0\n","    for sents in dev_gen():\n","        loss = sent_loss(sents)\n","        dev_loss += loss\n","        dev_words += sum(list(map(len, sents)))\n","    print ('Epoch %d: evaluation loss per word=%f' % (epoch, dev_loss/dev_words))\n","    \n","    # Keep track of the development accuracy and reduce the learning rate if it got worse\n","    if last_dev < dev_loss/dev_words:\n","        lr /= 2\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","        print ('learning rate decay to: ', lr)\n","    last_dev = dev_loss/dev_words\n","    \n","    # Save the word vectors\n","    if best_dev > dev_loss/dev_words:\n","        print ('Updating word vectors......')\n","        emb = model.embed.get_weights()[0]\n","        out_v = open(embed_path, 'w')\n","        out_w = open(words_path, 'w')\n","        for i in range(1, nwords+1):\n","            word = reverse_word_index[i]\n","            embedding = emb[i]\n","            out_w.write(word + \"\\n\")\n","            out_v.write('\\t'.join([str(x) for x in embedding]) + \"\\n\")\n","        out_v.close()\n","        out_w.close()\n","        best_dev = dev_loss/dev_words"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Start of epoch 0\n","Training time: 16.086 seconds, training loss at sentence 6400: 7.0107\n","Training time: 31.159 seconds, training loss at sentence 12800: 5.9164\n","Training time: 46.343 seconds, training loss at sentence 19200: 5.6515\n","Training time: 61.393 seconds, training loss at sentence 25600: 5.0926\n","Training time: 76.458 seconds, training loss at sentence 32000: 4.7780\n","Training time: 91.640 seconds, training loss at sentence 38400: 4.0376\n","Epoch 0: Training time=99.975 seconds, training loss per word=5.6934\n","Epoch 0: evaluation loss per word=7.208780\n","Updating word vectors......\n","Start of epoch 1\n","Training time: 15.463 seconds, training loss at sentence 6400: 3.1851\n","Training time: 31.020 seconds, training loss at sentence 12800: 2.0055\n","Training time: 46.122 seconds, training loss at sentence 19200: 1.4525\n","Training time: 61.642 seconds, training loss at sentence 25600: 1.0613\n","Training time: 76.642 seconds, training loss at sentence 32000: 0.9504\n","Training time: 92.388 seconds, training loss at sentence 38400: 1.0920\n","Epoch 1: Training time=100.827 seconds, training loss per word=1.9331\n","Epoch 1: evaluation loss per word=7.968989\n","learning rate decay to:  0.0005\n","Start of epoch 2\n","Training time: 14.983 seconds, training loss at sentence 6400: 1.1272\n","Training time: 31.083 seconds, training loss at sentence 12800: 0.5060\n","Training time: 46.078 seconds, training loss at sentence 19200: 0.3243\n","Training time: 61.087 seconds, training loss at sentence 25600: 0.2692\n","Training time: 76.031 seconds, training loss at sentence 32000: 0.2437\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-87f5d82e8e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Use the gradient tape to automatically retrieve the gradients of the trainable weights with respect to the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Run one step of gradient descent by updating the value of the weights to minimize the loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MaximumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MaximumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m   \u001b[0;34m\"\"\"Returns grad*(x > y, x <= y) with type of grad.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_MaximumMinimumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MaximumMinimumGrad\u001b[0;34m(op, grad, selector_op)\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0mxgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m   \u001b[0mygrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m   \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0mgy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mygrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(condition, x, y, name)\u001b[0m\n\u001b[1;32m   3229\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3232\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3233\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must both be non-None or both be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(condition, x, y, name)\u001b[0m\n\u001b[1;32m   9058\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9059\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9060\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9061\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9062\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2725,9650] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Select]"]}]},{"metadata":{"id":"JIqgcp51EEoW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}